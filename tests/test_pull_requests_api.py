#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Integration tests for pull request REST APIs.
These follow the structure used in issue comment tests so the suite stays consistent.
"""

from __future__ import annotations

import os
from pathlib import Path
from uuid import uuid4

import pytest
from requests import HTTPError

from core.api import GitHubRESTCrawler
from core.config import (
    GITHUB_REPO_NAME_TEST,
    GITHUB_REPO_OWNER_TEST,
    OUTPUT_DIR_TEST,
    get_github_token_test,
)

TEST_PULL_HEAD = os.getenv("GITHUB_TEST_PULL_HEAD")
TEST_PULL_BASE = os.getenv("GITHUB_TEST_PULL_BASE")


def _cleanup_output_artifacts():
    """Remove stale JSON files related to pull request tests."""
    output_path = Path(OUTPUT_DIR_TEST)
    output_path.mkdir(parents=True, exist_ok=True)
    patterns = [
        "pull_*_created.json",
        "pull_*_updated.json",
        "pull_*_files_page_*.json",
        "pull_*_commits_page_*.json",
        "pull_*.json",
        "repo_pulls.json",
    ]
    for pattern in patterns:
        for path in output_path.glob(pattern):
            try:
                path.unlink()
            except FileNotFoundError:
                continue


@pytest.fixture(scope="module")
def crawler() -> GitHubRESTCrawler:
    token = get_github_token_test()
    if not token:
        pytest.skip("GITHUB_TOKEN is required to run GitHub API tests.")
    return GitHubRESTCrawler(
        "edwardzcn-decade",
        "gh-easy-crawler",
        token,
        OUTPUT_DIR_TEST,
    )


@pytest.fixture(scope="module", autouse=True)
def prepare_environment():
    """Prepare local environment before running module tests."""
    print("ðŸ§© Preparing local test environment...")
    _cleanup_output_artifacts()
    yield
    print("âœ… Finished module tests, environment teardown complete.")


@pytest.fixture(scope="module")
def sample_pull(crawler: GitHubRESTCrawler) -> dict:
    pulls = crawler.list_repo_pulls(state="all", per_page=30, page=1)
    if not pulls:
        pytest.skip("Test repository has no pull requests to inspect.")
    return pulls[0]


def test_list_repo_pulls_creates_output(crawler: GitHubRESTCrawler):
    output_path = Path(OUTPUT_DIR_TEST) / "repo_pulls.json"
    if output_path.exists():
        output_path.unlink()

    pulls = crawler.list_repo_pulls(state="all", per_page=30, page=1)

    assert isinstance(pulls, list)
    assert output_path.exists()


def test_get_pull_matches_listing(crawler: GitHubRESTCrawler, sample_pull: dict):
    pull_number = sample_pull["number"]
    output_path = Path(OUTPUT_DIR_TEST) / f"pull_{pull_number}.json"
    if output_path.exists():
        output_path.unlink()

    fetched = crawler.get_pull(pull_number)

    assert fetched["number"] == pull_number
    assert fetched["title"] == sample_pull["title"]
    assert output_path.exists()


def test_list_pull_commits_and_files(crawler: GitHubRESTCrawler, sample_pull: dict):
    pull_number = sample_pull["number"]
    commits_path = Path(OUTPUT_DIR_TEST) / f"pull_{pull_number}_commits_page_1.json"
    files_path = Path(OUTPUT_DIR_TEST) / f"pull_{pull_number}_files_page_1.json"
    for candidate in (commits_path, files_path):
        if candidate.exists():
            candidate.unlink()

    commits = crawler.list_pull_commits(pull_number, per_page=30, page=1)
    files = crawler.list_pull_files(pull_number, per_page=30, page=1)

    assert isinstance(commits, list)
    assert isinstance(files, list)
    assert commits_path.exists()
    assert files_path.exists()


def test_is_pull_merged_reflects_status(crawler: GitHubRESTCrawler, sample_pull: dict):
    pull_number = sample_pull["number"]
    merged_flag = bool(sample_pull.get("merged_at"))

    if merged_flag:
        assert crawler.is_pull_merged(pull_number) is True
    else:
        with pytest.raises(HTTPError):
            crawler.is_pull_merged(pull_number)


@pytest.fixture
def pull_creation_inputs():
    if not TEST_PULL_HEAD or not TEST_PULL_BASE:
        pytest.skip(
            "Set GITHUB_TEST_PULL_HEAD and GITHUB_TEST_PULL_BASE to run creation tests."
        )
    return TEST_PULL_HEAD, TEST_PULL_BASE


def test_create_and_update_pull_request(
    crawler: GitHubRESTCrawler, pull_creation_inputs
):
    head, base = pull_creation_inputs
    title = f"[UT][pull] {uuid4().hex}"
    body = "Automated test pull request generated by test suite."

    created = crawler.create_pull(
        title=title,
        head=head,
        head_repo=crawler.repo_owner,
        base=base,
        body=body,
        draft=True,
        maintainer_can_modify=True,
    )
    pull_number = created["number"]
    created_output = Path(OUTPUT_DIR_TEST) / f"pull_{created['id']}_created.json"
    assert created["title"] == title
    assert created_output.exists()

    try:
        updated_title = f"{title} :: updated"
        updated_body = f"{body}\n\nUpdated by automated test."
        updated = crawler.update_pull(
            pull_number,
            title=updated_title,
            body=updated_body,
        )
        updated_output = Path(OUTPUT_DIR_TEST) / f"pull_{pull_number}_updated.json"
        assert updated["title"] == updated_title
        assert updated_output.exists()

    finally:
        try:
            crawler.update_pull(pull_number, state="closed")
        except Exception:
            pass
